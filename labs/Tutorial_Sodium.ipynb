{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial Sodium.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "m1WyX2Pezt5w",
        "6HGVdq5cJt6h",
        "QVBwNWseMlw2",
        "yzWpGENcPiYO",
        "ickoIjajWi3V",
        "WvFG0eBpv5t_",
        "w6Aj1em1v_Sa",
        "towjDjnOIAC1",
        "CZlg6jhhwFF2",
        "zTai68e3wHgb",
        "EgX0f71-voK2",
        "MLWZ7k7KiWkc"
      ],
      "authorship_tag": "ABX9TyN+ITADpBGMxcJTLsK3b5GV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmachlanski/iads-summer-school-causality-2022/blob/main/labs/Tutorial_Sodium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-ZZIkD8BaaC"
      },
      "source": [
        "# Causal Inference - Tutorial\n",
        "\n",
        "We are going to combine our knowledge of regression and classification methods to estimate causal effects in observational data.\n",
        "\n",
        "Steps we are going to take:\n",
        "1. Problem description.\n",
        "2. Importing packages.\n",
        "3. Loading and exploring the data.\n",
        "4. Data pre-processing.\n",
        "5. Training the models.\n",
        "6. Performance evaluation.\n",
        "7. Model selection (optional)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1WyX2Pezt5w"
      },
      "source": [
        "## Step 1 - problem setting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJfxTA4BPZ27"
      },
      "source": [
        "This is a simplified version of a model that simulates the effect of sodium intake on blood pressure. Officially proposed in ([Luque-Fernandez et al. 2019](https://academic.oup.com/ije/article/48/2/640/5248195)).\n",
        "\n",
        "\n",
        "We are given three covariates: age (A), sodium (S), and blood pressure (B). We are interested in the effect of sodium intake on blood pressure. In addition, we know that age affects both variables - confounder. Here is the assumed causal graph:\n",
        "\n",
        "![](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiYEDru-DhAl"
      },
      "source": [
        "The code that implements the simulation can be found in [sodium_generate.py](https://github.com/dmachlanski/iads-summer-school-causality-2022/blob/main/labs/sodium_generate.py) script. This data generation process can be also described as follows:\n",
        "\n",
        "$$A = \\mathcal{N}(65, 5)$$ \\\\\n",
        "$$\n",
        "S=\n",
        "    \\begin{cases}\n",
        "        1 & \\text{ if } A/18 + \\mathcal{N}(0, 1) > 3.5 \\\\ \n",
        "        0 & \\text{ otherwise } \n",
        "    \\end{cases}\n",
        "$$ \\\\\n",
        "$$B = ATE \\times S + 2 A + \\mathcal{N}(0, 1)$$ \\\\\n",
        "$$ATE = 1.05$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPTqN2HkE2Pz"
      },
      "source": [
        "Note we assume the same effect across the entire population and fix it to an arbitrary scalar.\n",
        "\n",
        "With this setting, we generate 10,000 samples and obtain file [sodium_10k.npz](https://github.com/dmachlanski/iads-summer-school-causality-2022/blob/main/labs/data/sodium_10k.npz).\n",
        "\n",
        "Because we know the true ATE used in the data generation process, we can evaluate our models' performance by measuring how close their predicted ATE ($\\widehat{ATE}$) is to the true one. More formally, we can write ATE as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfxqF2acGCB0"
      },
      "source": [
        "$$ATE = \\mathbb{E}[\\mathcal{Y}_1 - \\mathcal{Y}_0]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY8zTRZOHFcn"
      },
      "source": [
        "And predicted ATE as:\n",
        "\n",
        "$$\\widehat{ATE} = \\frac{1}{n}\\sum \\limits_{i=1}^{n}(\\hat{y}_1^{(i)} - \\hat{y}_0^{(i)})$$\n",
        "\n",
        "Where $\\hat{y}_t^{(i)}$ denotes predicted potential outcome for treatment $t$ and individual $(i)$. We can thus see that ATE is essentially the average of individual treatment effects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnVDCqdmFe_A"
      },
      "source": [
        "One commonly used metric that we will use here measures the absolute difference between the predicted and true ATE, that is:\n",
        "\n",
        "$$\\epsilon_{ATE} = \\left| \\widehat{ATE} - ATE \\right|$$\n",
        "\n",
        "We can implement this metric as the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYt3qo7iHGJ0"
      },
      "source": [
        "def ate_error(pred_te, true_ate):\n",
        "  \"\"\"\n",
        "  pred_te - collection of ITEs (list or array).\n",
        "  true_ate - true ATE (scalar)\n",
        "  \"\"\"\n",
        "  return np.abs(np.mean(pred_te) - true_ate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HGVdq5cJt6h"
      },
      "source": [
        "## Step 2 - packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udhdowJ8Jw3C"
      },
      "source": [
        "Google Colab has loads of pre-installed packages already. What if we need more? We can install additional packages by knowing that:\n",
        "- The exclamation mark ('!') gives us access to the Linux command line that runs behind our notebook.\n",
        "- We can access the default python's package manager with the command 'pip'.\n",
        "\n",
        "In our case, we are interested in using the [EconML](https://econml.azurewebsites.net/index.html) package, which is not part of the default Colab environment. We can install it via the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12hISSkts2bJ"
      },
      "source": [
        "!pip install econml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGDzbwBGMFwL"
      },
      "source": [
        "Note this command has to be executed everytime you restart the notebook.\n",
        "\n",
        "Now, we can import anything we need from EconML, together with the rest of the packages we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsdoBHUxtWPC"
      },
      "source": [
        "from econml.metalearners import XLearner\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVBwNWseMlw2"
      },
      "source": [
        "## Step 3 - data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ4d-KelM4DK"
      },
      "source": [
        "We are dealing here with the '.npz' file format. In order to access the data, the file can be either manually uploaded to Colab, or downloaded via the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxY0wgfFtj8U"
      },
      "source": [
        "!wget https://github.com/dmachlanski/iads-summer-school-causality-2022/raw/main/labs/data/sodium_10k.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AvBEAf5Nb0N"
      },
      "source": [
        "Let's load the file with numpy's 'load' function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtaff_ZittAW"
      },
      "source": [
        "data = np.load('sodium_10k.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIhlKjfTNhsA"
      },
      "source": [
        "We can see what variable names are available by examining the 'files' property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zzkcsd-tx6N"
      },
      "source": [
        "data.files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-nYh0hOBUyD"
      },
      "source": [
        "Variable names:\n",
        "- X -> A (age; background variable)\n",
        "- T -> S (sodium intake; treatment variable)\n",
        "- Y -> B (blood pressure; outcome variable)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeZ9y3I7tyvd"
      },
      "source": [
        "for f in data.files:\n",
        "  print(f'{f}: {data[f].shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaqzoR4zNzdw"
      },
      "source": [
        "As we can see above, we have three single-dimensional vectors, each of which consisting of 10,000 samples. We are going to reshape them to 2D vectors as some methods prefer this representation of data, though we will have to switch back and forth between 1D and 2D representation often as this requirement varies across methdos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei2NOfWJvmfN"
      },
      "source": [
        "X = data['x'].reshape(-1, 1)\n",
        "T = data['t'].reshape(-1, 1)\n",
        "Y = data['y'].reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKQLHJkHOm-L"
      },
      "source": [
        "Let's plot the distributions of all three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72uhd6sQ-od7"
      },
      "source": [
        "bins=20\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs[0].hist(X, bins=bins)\n",
        "axs[1].hist(T, bins=bins)\n",
        "axs[2].hist(Y, bins=bins)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAXdN29NOzE8"
      },
      "source": [
        "X and Y clearly follow the shape of the normal distribution, as expected. T is binary, i.e., consists of 0 and 1 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzWpGENcPiYO"
      },
      "source": [
        "## Step 4 - data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPbMWtKAuIRe"
      },
      "source": [
        "x_train, x_test, t_train, t_test, y_train, y_test = train_test_split(X, T, Y, test_size=0.2)\n",
        "\n",
        "scaler_x = StandardScaler()\n",
        "x_train = scaler_x.fit_transform(x_train)\n",
        "x_test = scaler_x.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqwQ6RAGPrfQ"
      },
      "source": [
        "## Step 5 - training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKXEFTm8V5LB"
      },
      "source": [
        "We are going to use three estimators here:\n",
        "- Random forest (RF; regressor).\n",
        "- Random forest with Inverse Propensity Weighting (IPW).\n",
        "- X-learner with RF as base learners."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ickoIjajWi3V"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvFG0eBpv5t_"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nxFxw8Yv8Fj"
      },
      "source": [
        "With random forests we simply model $P(Y|X, T)$, that is, we regress Y on X and T. Once trained, the model predicts potential outcomes $\\hat{y}_t^{(i)}$. Thus, to obtain ITE predictions for each individual, we need to predict both $\\hat{y}_0$ and $\\hat{y}_1$, that is, predict the outcomes for both control and treated settings for each individual.\n",
        "\n",
        "By calculating the difference between the treated and control outcome, we can obtain the effect per given individual. In other words:\n",
        "\n",
        "$$\\widehat{ITE}^{(i)} = \\hat{y}_1^{(i)} - \\hat{y}_0^{(i)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Aj1em1v_Sa"
      },
      "source": [
        "#### Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-u0hCF1vhQ2"
      },
      "source": [
        "# Random Forest\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Train on the training data.\n",
        "# In the supervised setting, our usual X here consists of X and T.\n",
        "# The target is Y - the outcome.\n",
        "# Input: [X, T], output: Y.\n",
        "rf.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten())\n",
        "\n",
        "# Predictions\n",
        "# Note we set T to a specific value for ALL individuals.\n",
        "# These are interventional distributions - P(Y|X, do(T=t)).\n",
        "\n",
        "# Training predictions:\n",
        "# Predict Y_0 given [X, 0]\n",
        "rf_y0_in = rf.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "# Predict Y_1 given [X, 1]\n",
        "rf_y1_in = rf.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "# Test predictions (model's generalisation to unseen examples):\n",
        "# Predict Y_0 given [X, 0]\n",
        "rf_y0_out = rf.predict(np.concatenate([x_test, np.zeros_like(t_test)], axis=1))\n",
        "# Predict Y_1 given [X, 1]\n",
        "rf_y1_out = rf.predict(np.concatenate([x_test, np.ones_like(t_test)], axis=1))\n",
        "\n",
        "# Compute ITEs (training and test)\n",
        "# ITE = Y_1 - Y_0\n",
        "rf_te_in = rf_y1_in - rf_y0_in\n",
        "rf_te_out = rf_y1_out - rf_y0_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "towjDjnOIAC1"
      },
      "source": [
        "### Random Forest with IPW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlg6jhhwFF2"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGBRoR2swHi6"
      },
      "source": [
        "This is a similar approach to the previous one, but extends it further with the Inverse Propensity Weighting (IPW). We proceed as follows:\n",
        "\n",
        "1. Use random forest classifier to model unit's probability of receiving the treatment, that is, $P(t_i|x_i)$. Input: X, target: T. Note this is classic binary classification problem. $P(t_i|x_i)$ is called a **propensity score**.\n",
        "2. Use trained classifier to predict propensity scores for each individual. Compute weights per each sample as:\n",
        "\n",
        "$$w_i = \\frac{t_i}{P(t_i|x_i)} + \\frac{1-t_i}{1-P(t_i|x_i)}$$\n",
        "\n",
        "Intuition: Dominant group gets smaller weights. In practice, gives more importance to treated samples.\n",
        "\n",
        "3. Use sample weights in random forest regressor training.\n",
        "4. Proceed with predictions as in the previous section.\n",
        "\n",
        "We can compute the sample weights with the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTSqYIewYX5"
      },
      "source": [
        "def get_ps_weights(clf, x, t):\n",
        "  ti = np.squeeze(t)\n",
        "  clf.fit(x, ti)\n",
        "  ptx = clf.predict_proba(x).T[1].T + 0.0001\n",
        "  return ti / ptx + ((1.0 - ti) / (1.0 - ptx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTai68e3wHgb"
      },
      "source": [
        "#### Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfguw3FCwmYz"
      },
      "source": [
        "# Get the sample weights\n",
        "prop_clf = RandomForestClassifier()\n",
        "weights = get_ps_weights(prop_clf, x_train, t_train)\n",
        "\n",
        "# Train the regressor\n",
        "rf_ipsw = RandomForestRegressor()\n",
        "rf_ipsw.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten(), sample_weight=weights)\n",
        "\n",
        "# Make predictions\n",
        "rf_ipsw_y0_in = rf_ipsw.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "rf_ipsw_y1_in = rf_ipsw.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "rf_ipsw_y0_out = rf_ipsw.predict(np.concatenate([x_test, np.zeros_like(t_test)], axis=1))\n",
        "rf_ipsw_y1_out = rf_ipsw.predict(np.concatenate([x_test, np.ones_like(t_test)], axis=1))\n",
        "\n",
        "rf_ipsw_te_in = rf_ipsw_y1_in - rf_ipsw_y0_in\n",
        "rf_ipsw_te_out = rf_ipsw_y1_out - rf_ipsw_y0_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Op8qjQsgn-f"
      },
      "source": [
        "### X-learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgX0f71-voK2"
      },
      "source": [
        "#### Formal description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IDYW7oiShp"
      },
      "source": [
        "A meta-learner implemented via EconML. Uses provided regressors and classifiers to solve smaller sub-problems. Models the effect directly instead of the outcomes, predicting ITEs as a consequence.\n",
        "\n",
        "Originally introduced in [(Künzel et al. 2019)](http://arxiv.org/abs/1706.03461). The modelling process of the X-learner can be divided into three stages.\n",
        "\n",
        "**Stage 1**\n",
        "\n",
        "Use provided regressors to model $\\mathcal{Y}_0$ and $\\mathcal{Y}_1$ separately. More formally, the response functions are:\n",
        "\n",
        "$$\\mu_0(x) = \\mathbb{E}[\\mathcal{Y}_0|X=x]$$\n",
        "$$\\mu_1(x) = \\mathbb{E}[\\mathcal{Y}_1|X=x]$$\n",
        "\n",
        "We denote estimated functions as $\\hat{\\mu}_0$ and $\\hat{\\mu}_1$.\n",
        "\n",
        "**Stage 2**\n",
        "\n",
        "Define imputed treatment effects as:\n",
        "\n",
        "$$\\mathcal{D}_0^{(i)} = \\hat{\\mu}_1(X_0^{(i)}) - \\mathcal{Y}_0^{(i)}$$\n",
        "$$\\mathcal{D}_1^{(i)} = \\mathcal{Y}_1^{(i)} - \\hat{\\mu}_0(X_1^{(i)})$$\n",
        "\n",
        "Use provided regressors to model $\\mathcal{D}_0$ and $\\mathcal{D}_1$ separately. The response functions are formally defined as:\n",
        "\n",
        "$$\\tau_0(x) = \\mathbb{E}[\\mathcal{D}_0|X=x]$$\n",
        "$$\\tau_1(x) = \\mathbb{E}[\\mathcal{D}_1|X=x]$$\n",
        "\n",
        "We denote estimated functions as $\\hat{\\tau}_0$ and $\\hat{\\tau}_1$.\n",
        "\n",
        "**Stage 3**\n",
        "\n",
        "The final treatment effect estimate is a weighted average of the two estimates from Stage 2:\n",
        "\n",
        "$$\\hat{\\tau}(x) = g(x)\\hat{\\tau}_0(x) + (1 - g(x))\\hat{\\tau}_1(x)$$\n",
        "\n",
        "Where $g \\in [0, 1]$ is a weight function. In practice, $g$ can be modelled as a propensity score function $e$, formally written as:\n",
        "\n",
        "$$e(x) = \\mathbb{E}[T|X=x]$$\n",
        "\n",
        "Using a provided classifier, we can obtain an estimate $\\hat{e}$ that can be used in place of $g$. That is:\n",
        "\n",
        "$$\\hat{\\tau}(x) = \\hat{e}(x)\\hat{\\tau}_0(x) + (1 - \\hat{e}(x))\\hat{\\tau}_1(x)$$\n",
        "\n",
        "In summary, we perform the following steps:\n",
        "1. Training (inputs: X, T, Y; outputs: $\\hat{\\tau}_0$, $\\hat{\\tau}_1$, $\\hat{e}$):\n",
        "  1. Model the outcomes with a provided regressor class and obtain estimators $\\hat{\\mu}_0$ and $\\hat{\\mu}_1$.\n",
        "  2. Make predictions $\\hat{\\mu}_1(X_0^{(i)})$ and $\\hat{\\mu}_0(X_1^{(i)})$.\n",
        "  3. Compute imputed treatment effects $\\mathcal{D}_0$ and $\\mathcal{D}_1$.\n",
        "  4. Model the imputed treatment effects with a provided regressor class and obtain estimators $\\hat{\\tau}_0$ and $\\hat{\\tau}_1$.\n",
        "  5. Model the propensity scores with a provided classifier class and obtain an estimator $\\hat{e}$.\n",
        "2. Prediction (inputs: X; outputs: $\\widehat{ITE}$):\n",
        "  1. Use estimator $\\hat{\\tau}$ to obtain individual treatment effect estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLWZ7k7KiWkc"
      },
      "source": [
        "#### Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60Kh3Cv3wuUa"
      },
      "source": [
        "We continue with random forests here by providing the X-learner with RF regressor and RF classifier as base learners. Note it distinguishes X from T in its input - it is necessary to learn the propensity score estimator. Also, the final prediction does not depend on T! Though it does indirectly by predicting the propensity score internally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IWeKlOOvQfy"
      },
      "source": [
        "# X-Learner\n",
        "xl = XLearner(models=RandomForestRegressor(), propensity_model=RandomForestClassifier())\n",
        "xl.fit(y_train, t_train.flatten(), X=x_train)\n",
        "\n",
        "xl_te_in = xl.effect(x_train)\n",
        "xl_te_out = xl.effect(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_DyjDFLPyyO"
      },
      "source": [
        "## Step 6 - evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CacdEXLFiH9g"
      },
      "source": [
        "We will examine our estimators' performance from different perspectives:\n",
        "- ATE error\n",
        "- Confidence intervals of predicted ATEs\n",
        "- Visualisations of predicted effects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQhziISdjRtz"
      },
      "source": [
        "### ATE error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt1ARZ-AwyqN"
      },
      "source": [
        "true_ate = 1.05\n",
        "\n",
        "rf_ate_in = ate_error(rf_te_in, true_ate)\n",
        "rf_ate_out = ate_error(rf_te_out, true_ate)\n",
        "\n",
        "rf_ipsw_ate_in = ate_error(rf_ipsw_te_in, true_ate)\n",
        "rf_ipsw_ate_out = ate_error(rf_ipsw_te_out, true_ate)\n",
        "\n",
        "xl_ate_in = ate_error(xl_te_in, true_ate)\n",
        "xl_ate_out = ate_error(xl_te_out, true_ate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejaGko09xiQs"
      },
      "source": [
        "results = []\n",
        "results.append(['RF', rf_ate_in, rf_ate_out])\n",
        "results.append(['RF (IPW)', rf_ipsw_ate_in, rf_ipsw_ate_out])\n",
        "results.append(['XL', xl_ate_in, xl_ate_out])\n",
        "\n",
        "cols = ['Method', 'ATE train', 'ATE test']\n",
        "\n",
        "df = pd.DataFrame(results, columns=cols)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s1ToJZljU7M"
      },
      "source": [
        "### Confidence intervals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LwtO9NLxiOc"
      },
      "source": [
        "def mean_ci(data, ci=0.95):\n",
        "  l_mean = np.mean(data)\n",
        "  lower, upper = st.t.interval(ci, len(data)-1, loc=l_mean, scale=st.sem(data))\n",
        "  return l_mean, lower, upper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iMAuhzCyfNk"
      },
      "source": [
        "rf_ate_bounds = mean_ci(rf_te_out)\n",
        "rf_ipsw_ate_bounds = mean_ci(rf_ipsw_te_out)\n",
        "xl_ate_bounds = mean_ci(xl_te_out)\n",
        "\n",
        "results = []\n",
        "results.append(['RF', rf_ate_bounds[0], rf_ate_bounds[1], rf_ate_bounds[2]])\n",
        "results.append(['RF (IPW)', rf_ipsw_ate_bounds[0], rf_ipsw_ate_bounds[1], rf_ipsw_ate_bounds[2]])\n",
        "results.append(['XL', xl_ate_bounds[0], xl_ate_bounds[1], xl_ate_bounds[2]])\n",
        "\n",
        "cols = ['Method', 'ATE mean', 'CI lower', 'CI upper']\n",
        "\n",
        "df = pd.DataFrame(results, columns=cols)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FamneAp_jnY4"
      },
      "source": [
        "### Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O01KtZ1dzNWH"
      },
      "source": [
        "plt.figure()\n",
        "plt.boxplot([rf_te_out, rf_ipsw_te_out, xl_te_out.flatten()], labels=['RF', 'RF (IPW)', 'X-learner'])\n",
        "plt.ylabel('Treatment Effect')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjD5k5Q2zNUI"
      },
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "m_size = 10\n",
        "plt.scatter(x_test, rf_te_out, label=\"RF\", s=m_size)\n",
        "plt.scatter(x_test, rf_ipsw_te_out, label=\"RF (IPW)\", s=m_size)\n",
        "plt.scatter(x_test, xl_te_out, label=\"X-learner\", s=m_size)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Treatment Effect')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6jsDWVVpuOT"
      },
      "source": [
        "## Step 7 - model selection\n",
        "\n",
        "So far, we have used regressors and classifiers with default hyperparameters. In real experiments and applications, you will likely want to optimise your estimators at least to some extent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmmz1HKXqczQ"
      },
      "source": [
        "# Defines parameter search space for Random Forests.\n",
        "params = {\"max_leaf_nodes\": [10, 20, 30, None], \"max_depth\": [5, 10, 20, None]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ7ooM8ougm5"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgp84Xc1qvhG"
      },
      "source": [
        "rf = GridSearchCV(RandomForestRegressor(), param_grid=params, n_jobs=-1, cv=5)\n",
        "\n",
        "rf.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten())\n",
        "\n",
        "rf_y0_in = rf.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "rf_y1_in = rf.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "rf_y0_out = rf.predict(np.concatenate([x_test, np.zeros_like(t_test)], axis=1))\n",
        "rf_y1_out = rf.predict(np.concatenate([x_test, np.ones_like(t_test)], axis=1))\n",
        "\n",
        "rf_te_in = rf_y1_in - rf_y0_in\n",
        "rf_te_out = rf_y1_out - rf_y0_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8XRpHaguliF"
      },
      "source": [
        "### Random Forest with IPW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wglx3AFrTXl"
      },
      "source": [
        "prop_clf = GridSearchCV(RandomForestClassifier(), param_grid=params, n_jobs=-1, cv=5)\n",
        "weights = get_ps_weights(prop_clf, x_train, t_train)\n",
        "\n",
        "rf_ipsw = GridSearchCV(RandomForestRegressor(), param_grid=params, n_jobs=-1, cv=5)\n",
        "rf_ipsw.fit(np.concatenate([x_train, t_train], axis=1), y_train.flatten(), sample_weight=weights)\n",
        "\n",
        "rf_ipsw_y0_in = rf_ipsw.predict(np.concatenate([x_train, np.zeros_like(t_train)], axis=1))\n",
        "rf_ipsw_y1_in = rf_ipsw.predict(np.concatenate([x_train, np.ones_like(t_train)], axis=1))\n",
        "\n",
        "rf_ipsw_y0_out = rf_ipsw.predict(np.concatenate([x_test, np.zeros_like(t_test)], axis=1))\n",
        "rf_ipsw_y1_out = rf_ipsw.predict(np.concatenate([x_test, np.ones_like(t_test)], axis=1))\n",
        "\n",
        "rf_ipsw_te_in = rf_ipsw_y1_in - rf_ipsw_y0_in\n",
        "rf_ipsw_te_out = rf_ipsw_y1_out - rf_ipsw_y0_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfOuyIW7up4_"
      },
      "source": [
        "### X-Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSCRCu91sKf_"
      },
      "source": [
        "reg = GridSearchCV(RandomForestRegressor(), param_grid=params, n_jobs=-1, cv=5)\n",
        "clf = GridSearchCV(RandomForestClassifier(), param_grid=params, n_jobs=-1, cv=5)\n",
        "\n",
        "xl = XLearner(models=reg, propensity_model=clf)\n",
        "xl.fit(y_train, t_train.flatten(), X=x_train)\n",
        "\n",
        "xl_te_in = xl.effect(x_train)\n",
        "xl_te_out = xl.effect(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gb4-B_ruwX3"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1es-6aZt6_5"
      },
      "source": [
        "true_ate = 1.05\n",
        "\n",
        "rf_ate_in = ate_error(rf_te_in, true_ate)\n",
        "rf_ate_out = ate_error(rf_te_out, true_ate)\n",
        "\n",
        "rf_ipsw_ate_in = ate_error(rf_ipsw_te_in, true_ate)\n",
        "rf_ipsw_ate_out = ate_error(rf_ipsw_te_out, true_ate)\n",
        "\n",
        "xl_ate_in = ate_error(xl_te_in, true_ate)\n",
        "xl_ate_out = ate_error(xl_te_out, true_ate)\n",
        "\n",
        "results = []\n",
        "results.append(['RF', rf_ate_in, rf_ate_out])\n",
        "results.append(['RF (IPW)', rf_ipsw_ate_in, rf_ipsw_ate_out])\n",
        "results.append(['XL', xl_ate_in, xl_ate_out])\n",
        "\n",
        "cols = ['Method', 'ATE train', 'ATE test']\n",
        "\n",
        "df = pd.DataFrame(results, columns=cols)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}